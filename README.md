<h1 align="center">Swag algotith</h1>

<h2>Repositorio:</h2>

Este es el link del [repositorio](https://github.com/claudiaalozano/algorith_SWAG.git)

***
<h2>¿De qué trata esta tarea?</h2>
En esta tarea se nos presenta un paper el cual debemos analizar y sacar conclusiones.

***
## Integrantes:

1. [Alba](https://github.com/albabernal03) 
2. [Carmen](https://github.com/carmenm02)
3. [Laura](https://github.com/lauralardies)
4. [Carlota](https://github.com/crltsnch)
5. [Claudia](https://github.com/claudiaalozano)


## Conclusiones:


El paper propuesto presenta datos curiosos e interesantes, así que a continuación vamos a presentar nuestra conclusión. 
Presenta una muy buena idea o el concepto en general es muy bueno. Aunque aproximar funciones matemáticas mediante redes neuronales es una idea que pensamos que es más fácil mediante otros métodos (como métodos numéricos e interpolación numérica), pero el poder obtener una salida polinómica en vez de lineal es en cierto modo interesante.   
También se nombra que puede ser usada en CNN pero no se muestra en el paper por algún motivo. Los otros tipos de redes como RNNs, CNNs, LSTMs y demás, estaría bien verlas en práctica ya que con el dataset MNIST refleja buenos resultados.
En conclusión la idea de usar los inputs como exponentes, se nos ocurrió que podríamos cambiarlos por un vector de k componentes con cada valor elevado a la k-ésima componente, para usar menos inputs y compactar la red neuronal.
